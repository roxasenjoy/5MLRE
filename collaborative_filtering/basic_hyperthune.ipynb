{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4490f05f-556f-4bc7-ae47-1f78028f760d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b88c931-978e-48a3-92c7-82bf28fd39ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data\\anime.csv\n",
      "../data\\rating.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('../data'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e19ff25-1610-4f7a-a011-979f444f762d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_summary as ps\n",
    "from surprise import Reader\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import cross_validate, KFold, GridSearchCV\n",
    "from surprise import SVD, NMF, SlopeOne, KNNBasic, KNNWithMeans, KNNBaseline, CoClustering, BaselineOnly, NormalPredictor\n",
    "from surprise.accuracy import rmse\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "import datetime\n",
    "from operator import itemgetter\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.prediction_algorithms.co_clustering import CoClustering\n",
    "from surprise.prediction_algorithms.knns import KNNBasic\n",
    "from surprise.prediction_algorithms.matrix_factorization import SVDpp, SVD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5145e5f0-67ed-4ea1-8a2f-a68d2a54e9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d448769b-c257-49d1-b762-563ce11cea5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '../data/'\n",
    "anime_df = pd.read_csv(folder+'anime.csv')\n",
    "rate_df = pd.read_csv(folder+'rating.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0494cb6e-99f2-46de-a95a-78ac06977e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anime:  (12294, 7)\n",
      "rating:  (7813737, 3)\n"
     ]
    }
   ],
   "source": [
    "print('anime: ', anime_df.shape)\n",
    "print('rating: ', rate_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "373730ad-e963-4ac1-8626-d42484e2909c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   anime_id                              name  \\\n0     32281                    Kimi no Na wa.   \n1      5114  Fullmetal Alchemist: Brotherhood   \n2     28977                          Gintama°   \n3      9253                       Steins;Gate   \n4      9969                     Gintama&#039;   \n\n                                               genre   type episodes  rating  \\\n0               Drama, Romance, School, Supernatural  Movie        1    9.37   \n1  Action, Adventure, Drama, Fantasy, Magic, Mili...     TV       64    9.26   \n2  Action, Comedy, Historical, Parody, Samurai, S...     TV       51    9.25   \n3                                   Sci-Fi, Thriller     TV       24    9.17   \n4  Action, Comedy, Historical, Parody, Samurai, S...     TV       51    9.16   \n\n   members  \n0   200630  \n1   793665  \n2   114262  \n3   673572  \n4   151266  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>anime_id</th>\n      <th>name</th>\n      <th>genre</th>\n      <th>type</th>\n      <th>episodes</th>\n      <th>rating</th>\n      <th>members</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>32281</td>\n      <td>Kimi no Na wa.</td>\n      <td>Drama, Romance, School, Supernatural</td>\n      <td>Movie</td>\n      <td>1</td>\n      <td>9.37</td>\n      <td>200630</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5114</td>\n      <td>Fullmetal Alchemist: Brotherhood</td>\n      <td>Action, Adventure, Drama, Fantasy, Magic, Mili...</td>\n      <td>TV</td>\n      <td>64</td>\n      <td>9.26</td>\n      <td>793665</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>28977</td>\n      <td>Gintama°</td>\n      <td>Action, Comedy, Historical, Parody, Samurai, S...</td>\n      <td>TV</td>\n      <td>51</td>\n      <td>9.25</td>\n      <td>114262</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9253</td>\n      <td>Steins;Gate</td>\n      <td>Sci-Fi, Thriller</td>\n      <td>TV</td>\n      <td>24</td>\n      <td>9.17</td>\n      <td>673572</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9969</td>\n      <td>Gintama&amp;#039;</td>\n      <td>Action, Comedy, Historical, Parody, Samurai, S...</td>\n      <td>TV</td>\n      <td>51</td>\n      <td>9.16</td>\n      <td>151266</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anime_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed34beff-3c3d-4e1f-b2dc-38fa12a47901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "     user_id  anime_id  rating_x                    name  \\\n47         1      8074        10  Highschool of the Dead   \n81         1     11617        10         High School DxD   \n83         1     11757        10        Sword Art Online   \n101        1     15451        10     High School DxD New   \n153        2     11771        10        Kuroko no Basket   \n\n                                                 genre type episodes  \\\n47                 Action, Ecchi, Horror, Supernatural   TV       12   \n81       Comedy, Demons, Ecchi, Harem, Romance, School   TV       12   \n83           Action, Adventure, Fantasy, Game, Romance   TV       25   \n101  Action, Comedy, Demons, Ecchi, Harem, Romance,...   TV       12   \n153                    Comedy, School, Shounen, Sports   TV       25   \n\n     rating_y   members  \n47       7.46  535892.0  \n81       7.70  398660.0  \n83       7.83  893100.0  \n101      7.87  266657.0  \n153      8.46  338315.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>anime_id</th>\n      <th>rating_x</th>\n      <th>name</th>\n      <th>genre</th>\n      <th>type</th>\n      <th>episodes</th>\n      <th>rating_y</th>\n      <th>members</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>47</th>\n      <td>1</td>\n      <td>8074</td>\n      <td>10</td>\n      <td>Highschool of the Dead</td>\n      <td>Action, Ecchi, Horror, Supernatural</td>\n      <td>TV</td>\n      <td>12</td>\n      <td>7.46</td>\n      <td>535892.0</td>\n    </tr>\n    <tr>\n      <th>81</th>\n      <td>1</td>\n      <td>11617</td>\n      <td>10</td>\n      <td>High School DxD</td>\n      <td>Comedy, Demons, Ecchi, Harem, Romance, School</td>\n      <td>TV</td>\n      <td>12</td>\n      <td>7.70</td>\n      <td>398660.0</td>\n    </tr>\n    <tr>\n      <th>83</th>\n      <td>1</td>\n      <td>11757</td>\n      <td>10</td>\n      <td>Sword Art Online</td>\n      <td>Action, Adventure, Fantasy, Game, Romance</td>\n      <td>TV</td>\n      <td>25</td>\n      <td>7.83</td>\n      <td>893100.0</td>\n    </tr>\n    <tr>\n      <th>101</th>\n      <td>1</td>\n      <td>15451</td>\n      <td>10</td>\n      <td>High School DxD New</td>\n      <td>Action, Comedy, Demons, Ecchi, Harem, Romance,...</td>\n      <td>TV</td>\n      <td>12</td>\n      <td>7.87</td>\n      <td>266657.0</td>\n    </tr>\n    <tr>\n      <th>153</th>\n      <td>2</td>\n      <td>11771</td>\n      <td>10</td>\n      <td>Kuroko no Basket</td>\n      <td>Comedy, School, Shounen, Sports</td>\n      <td>TV</td>\n      <td>25</td>\n      <td>8.46</td>\n      <td>338315.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df = rate_df.merge(anime_df, how='left', left_on=['anime_id'], right_on=['anime_id'])\n",
    "df = full_df[full_df['rating_x'] != -1]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e21758f5-3523-48ca-a2a7-dedde4df5769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categoricals:  ['name', 'genre', 'type', 'episodes']\n",
      "numerics:  ['user_id', 'anime_id', 'rating_x', 'rating_y', 'members']\n"
     ]
    },
    {
     "data": {
      "text/plain": "                   user_id     anime_id   rating_x         name        genre  \\\ncount            7813737.0    7813737.0  7813737.0          NaN          NaN   \nmean          36727.956745  8909.072104    6.14403          NaN          NaN   \nstd           20997.946119  8883.949636     3.7278          NaN          NaN   \nmin                    1.0          1.0       -1.0          NaN          NaN   \n25%                18974.0       1240.0        6.0          NaN          NaN   \n50%                36791.0       6213.0        7.0          NaN          NaN   \n75%                54757.0      14093.0        9.0          NaN          NaN   \nmax                73516.0      34519.0       10.0          NaN          NaN   \ncounts             7813737      7813737    7813737      7813727      7813617   \nuniques              73515        11200         11        11196         3154   \nmissing                  0            0          0           10          120   \nmissing_perc            0%           0%         0%        0.00%        0.00%   \ntypes              numeric      numeric    numeric  categorical  categorical   \n\n                     type     episodes   rating_y        members  \ncount                 NaN          NaN  7813721.0      7813727.0  \nmean                  NaN          NaN   7.653127  178620.804981  \nstd                   NaN          NaN   0.673029  188176.417151  \nmin                   NaN          NaN       1.67           29.0  \n25%                   NaN          NaN       7.27        44030.0  \n50%                   NaN          NaN       7.68       110470.0  \n75%                   NaN          NaN       8.13       244268.0  \nmax                   NaN          NaN        9.5      1013917.0  \ncounts            7813723      7813727    7813721        7813727  \nuniques                 6          184        585           6487  \nmissing                14           10         16             10  \nmissing_perc        0.00%        0.00%      0.00%          0.00%  \ntypes         categorical  categorical    numeric        numeric  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>anime_id</th>\n      <th>rating_x</th>\n      <th>name</th>\n      <th>genre</th>\n      <th>type</th>\n      <th>episodes</th>\n      <th>rating_y</th>\n      <th>members</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>7813737.0</td>\n      <td>7813737.0</td>\n      <td>7813737.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>7813721.0</td>\n      <td>7813727.0</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>36727.956745</td>\n      <td>8909.072104</td>\n      <td>6.14403</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>7.653127</td>\n      <td>178620.804981</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>20997.946119</td>\n      <td>8883.949636</td>\n      <td>3.7278</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.673029</td>\n      <td>188176.417151</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>-1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.67</td>\n      <td>29.0</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>18974.0</td>\n      <td>1240.0</td>\n      <td>6.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>7.27</td>\n      <td>44030.0</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>36791.0</td>\n      <td>6213.0</td>\n      <td>7.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>7.68</td>\n      <td>110470.0</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>54757.0</td>\n      <td>14093.0</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>8.13</td>\n      <td>244268.0</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>73516.0</td>\n      <td>34519.0</td>\n      <td>10.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9.5</td>\n      <td>1013917.0</td>\n    </tr>\n    <tr>\n      <th>counts</th>\n      <td>7813737</td>\n      <td>7813737</td>\n      <td>7813737</td>\n      <td>7813727</td>\n      <td>7813617</td>\n      <td>7813723</td>\n      <td>7813727</td>\n      <td>7813721</td>\n      <td>7813727</td>\n    </tr>\n    <tr>\n      <th>uniques</th>\n      <td>73515</td>\n      <td>11200</td>\n      <td>11</td>\n      <td>11196</td>\n      <td>3154</td>\n      <td>6</td>\n      <td>184</td>\n      <td>585</td>\n      <td>6487</td>\n    </tr>\n    <tr>\n      <th>missing</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>10</td>\n      <td>120</td>\n      <td>14</td>\n      <td>10</td>\n      <td>16</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>missing_perc</th>\n      <td>0%</td>\n      <td>0%</td>\n      <td>0%</td>\n      <td>0.00%</td>\n      <td>0.00%</td>\n      <td>0.00%</td>\n      <td>0.00%</td>\n      <td>0.00%</td>\n      <td>0.00%</td>\n    </tr>\n    <tr>\n      <th>types</th>\n      <td>numeric</td>\n      <td>numeric</td>\n      <td>numeric</td>\n      <td>categorical</td>\n      <td>categorical</td>\n      <td>categorical</td>\n      <td>categorical</td>\n      <td>numeric</td>\n      <td>numeric</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = ps.DataFrameSummary(full_df)\n",
    "print('categoricals: ', dfs.categoricals.tolist())\n",
    "print('numerics: ', dfs.numerics.tolist())\n",
    "dfs.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3647106e-1d3b-4827-9173-11af4617436f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original data frame shape:\t(6337241, 9)\n",
      "The new data frame shape:\t(2368822, 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": "         user_id  anime_id  rating_x  \\\n302            5         6         8   \n303            5        15         6   \n304            5        17         6   \n305            5        18         6   \n306            5        20         6   \n...          ...       ...       ...   \n7813329    73507      8211         5   \n7813331    73507      8348         5   \n7813332    73507      8440         7   \n7813333    73507      8769         8   \n7813334    73507     10067         5   \n\n                                                 name  \\\n302                                            Trigun   \n303                                      Eyeshield 21   \n304                        Hungry Heart: Wild Striker   \n305                            Initial D Fourth Stage   \n306                                            Naruto   \n...                                               ...   \n7813329               Dance in the Vampire Bund Recap   \n7813331  Tengen Toppa Gurren Lagann: Parallel Works 2   \n7813332                            Black Lagoon Omake   \n7813333   Ore no Imouto ga Konnani Kawaii Wake ga Nai   \n7813334                Angel Beats!: Another Epilogue   \n\n                                                     genre     type episodes  \\\n302                                 Action, Comedy, Sci-Fi       TV       26   \n303                        Action, Comedy, Shounen, Sports       TV      145   \n304                 Comedy, Shounen, Slice of Life, Sports       TV       52   \n305                    Action, Cars, Drama, Seinen, Sports       TV       24   \n306      Action, Comedy, Martial Arts, Shounen, Super P...       TV      220   \n...                                                    ...      ...      ...   \n7813329                      Action, Supernatural, Vampire  Special        1   \n7813331                                       Mecha, Music    Music        7   \n7813332                                             Comedy  Special        7   \n7813333                      Comedy, Seinen, Slice of Life       TV       12   \n7813334                        Drama, School, Supernatural  Special        1   \n\n         rating_y   members  \n302          8.32  283069.0  \n303          8.08   83648.0  \n304          7.74   13469.0  \n305          8.24   41584.0  \n306          7.81  683297.0  \n...           ...       ...  \n7813329      6.61    9758.0  \n7813331      7.09   13361.0  \n7813332      7.02   33923.0  \n7813333      7.49  321477.0  \n7813334      7.63  134180.0  \n\n[2368822 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>anime_id</th>\n      <th>rating_x</th>\n      <th>name</th>\n      <th>genre</th>\n      <th>type</th>\n      <th>episodes</th>\n      <th>rating_y</th>\n      <th>members</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>302</th>\n      <td>5</td>\n      <td>6</td>\n      <td>8</td>\n      <td>Trigun</td>\n      <td>Action, Comedy, Sci-Fi</td>\n      <td>TV</td>\n      <td>26</td>\n      <td>8.32</td>\n      <td>283069.0</td>\n    </tr>\n    <tr>\n      <th>303</th>\n      <td>5</td>\n      <td>15</td>\n      <td>6</td>\n      <td>Eyeshield 21</td>\n      <td>Action, Comedy, Shounen, Sports</td>\n      <td>TV</td>\n      <td>145</td>\n      <td>8.08</td>\n      <td>83648.0</td>\n    </tr>\n    <tr>\n      <th>304</th>\n      <td>5</td>\n      <td>17</td>\n      <td>6</td>\n      <td>Hungry Heart: Wild Striker</td>\n      <td>Comedy, Shounen, Slice of Life, Sports</td>\n      <td>TV</td>\n      <td>52</td>\n      <td>7.74</td>\n      <td>13469.0</td>\n    </tr>\n    <tr>\n      <th>305</th>\n      <td>5</td>\n      <td>18</td>\n      <td>6</td>\n      <td>Initial D Fourth Stage</td>\n      <td>Action, Cars, Drama, Seinen, Sports</td>\n      <td>TV</td>\n      <td>24</td>\n      <td>8.24</td>\n      <td>41584.0</td>\n    </tr>\n    <tr>\n      <th>306</th>\n      <td>5</td>\n      <td>20</td>\n      <td>6</td>\n      <td>Naruto</td>\n      <td>Action, Comedy, Martial Arts, Shounen, Super P...</td>\n      <td>TV</td>\n      <td>220</td>\n      <td>7.81</td>\n      <td>683297.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7813329</th>\n      <td>73507</td>\n      <td>8211</td>\n      <td>5</td>\n      <td>Dance in the Vampire Bund Recap</td>\n      <td>Action, Supernatural, Vampire</td>\n      <td>Special</td>\n      <td>1</td>\n      <td>6.61</td>\n      <td>9758.0</td>\n    </tr>\n    <tr>\n      <th>7813331</th>\n      <td>73507</td>\n      <td>8348</td>\n      <td>5</td>\n      <td>Tengen Toppa Gurren Lagann: Parallel Works 2</td>\n      <td>Mecha, Music</td>\n      <td>Music</td>\n      <td>7</td>\n      <td>7.09</td>\n      <td>13361.0</td>\n    </tr>\n    <tr>\n      <th>7813332</th>\n      <td>73507</td>\n      <td>8440</td>\n      <td>7</td>\n      <td>Black Lagoon Omake</td>\n      <td>Comedy</td>\n      <td>Special</td>\n      <td>7</td>\n      <td>7.02</td>\n      <td>33923.0</td>\n    </tr>\n    <tr>\n      <th>7813333</th>\n      <td>73507</td>\n      <td>8769</td>\n      <td>8</td>\n      <td>Ore no Imouto ga Konnani Kawaii Wake ga Nai</td>\n      <td>Comedy, Seinen, Slice of Life</td>\n      <td>TV</td>\n      <td>12</td>\n      <td>7.49</td>\n      <td>321477.0</td>\n    </tr>\n    <tr>\n      <th>7813334</th>\n      <td>73507</td>\n      <td>10067</td>\n      <td>5</td>\n      <td>Angel Beats!: Another Epilogue</td>\n      <td>Drama, School, Supernatural</td>\n      <td>Special</td>\n      <td>1</td>\n      <td>7.63</td>\n      <td>134180.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2368822 rows × 9 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_anime_ratings = 250\n",
    "filter_anime = df['anime_id'].value_counts() > min_anime_ratings\n",
    "filter_anime = filter_anime[filter_anime].index.tolist()\n",
    "\n",
    "min_user_ratings = 250\n",
    "filter_users = df['user_id'].value_counts() > min_user_ratings\n",
    "filter_users = filter_users[filter_users].index.tolist()\n",
    "\n",
    "df_new = df[(df['anime_id'].isin(filter_anime)) & (df['user_id'].isin(filter_users))]\n",
    "print('The original data frame shape:\\t{}'.format(df.shape))\n",
    "print('The new data frame shape:\\t{}'.format(df_new.shape))\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66712fc9-ec82-4638-a45e-8130dca4ff95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<surprise.dataset.DatasetAutoFolds at 0x1c21d1d9cd0>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader = Reader(rating_scale=(0, 10))\n",
    "data = Dataset.load_from_df(df_new[['user_id', 'anime_id', 'rating_x']], reader)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022efa17-65f2-402b-8246-6ef005340a28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2adbc612-b8d2-4242-9008-e5c9dfebc7d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'test_rmse': array([1.08680414, 1.08698493, 1.08565772, 1.0859979 , 1.08790055]),\n 'fit_time': (42.9102246761322,\n  54.62861180305481,\n  44.71566462516785,\n  61.5068244934082,\n  58.54916048049927),\n 'test_time': (12.38604211807251,\n  9.806036472320557,\n  12.418980360031128,\n  15.543078422546387,\n  13.923075914382935)}"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo = SVD(biased=False)\n",
    "cross_validate(algo, data, measures=['RMSE'], cv=5, verbose=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f18824d-a0f2-49ec-8a15-e3bbebca4260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperTune(data, modelTarget, leaveOneOut=False):\n",
    "    if modelTarget == \"als\":\n",
    "        param_grid = {\"bsl_options\": {\"n_epochs\": epochs, \"reg_u\": regUs, \"reg_i\": regIs, \"method\": [\"als\"]}}\n",
    "    else:\n",
    "        param_grid = {\"bsl_options\": {\"n_epochs\": epochs, \"learning_rate\": lRates, \"method\": [\"sgd\"]}}\n",
    "\n",
    "    if leaveOneOut:\n",
    "        gs = GridSearchCV(BaselineOnly, param_grid, measures=[\"rmse\", \"mae\"], cv=LeaveOneOut())\n",
    "\n",
    "    else:\n",
    "        gs = GridSearchCV(BaselineOnly, param_grid, measures=[\"rmse\", \"mae\"], cv=5)\n",
    "\n",
    "    gs.fit(data)\n",
    "\n",
    "    print(\"RMSE score\", gs.best_score['rmse'], \" with \", gs.best_params)\n",
    "\n",
    "    return (gs.best_score['mae'], gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70eecc50-a4dd-441a-b840-0037c4e9453d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainset, testset = train_test_split(data, test_size=0.25)\n",
    "# randAlgorith = random_pred.NormalPredictor()\n",
    "# randAlgorith.fit(trainset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0c1f6e6-13f2-4b42-935c-af94eca82dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "RMSE score 1.1584663526307317  with  {'rmse': {'bsl_options': {'n_epochs': 10, 'reg_u': 5, 'reg_i': 5, 'method': 'als'}}, 'mae': {'bsl_options': {'n_epochs': 10, 'reg_u': 5, 'reg_i': 5, 'method': 'als'}}}\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "RMSE score 1.16001500094048  with  {'rmse': {'bsl_options': {'n_epochs': 10, 'learning_rate': 0.005, 'method': 'sgd'}}, 'mae': {'bsl_options': {'n_epochs': 10, 'learning_rate': 0.005, 'method': 'sgd'}}}\n",
      "best model : {'bsl_options': {'n_epochs': 10, 'reg_u': 5, 'reg_i': 5, 'method': 'als'}}\n"
     ]
    }
   ],
   "source": [
    "method = [\"als\", \"sgd\"]\n",
    "epochs = [5, 10]\n",
    "regUs = [5, 10, 15, 20]\n",
    "regIs = [5, 10, 15, 20]\n",
    "lRates = [0.05, 0.005, 0.0005]\n",
    "\n",
    "setOfValue = [hyperTune(data, \"als\"),  hyperTune(data, \"sgd\")]\n",
    "print(\"best model : \"+str(min(setOfValue,key=itemgetter(0))[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b18342a-0a6f-4e1a-bbde-640da5cc03e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=5, random_state=777)\n",
    "cvSlope = KFold(n_splits=2, random_state=777)\n",
    "targets = [\n",
    "           {\"name\": \"Co-clustering\", \"param_grid\": {\"n_epochs\": [20, 30], \"n_cltr_u\": [3, 6], \"n_cltr_i\": [3, 6]},\"verbose\": [False], \"model\": CoClustering, \"CV\": cv},\n",
    "           {\"name\":\"Slope one\", \"param_grid\": {}, \"verbose\": [False], \"model\": SlopeOne, \"CV\":cvSlope},\n",
    "           {\"name\":\"knn basic\",\"param_grid\":{\"sim_options\": {\"name\": [\"msd\"], \"min_support\":[2,5,10]}, \"k\": [30,40], \"min_k\": [1,10], \"verbose\": [False], \"user_based\": [True, False]},\"model\":KNNBasic, \"CV\":cv},\n",
    "           {\"name\":\"Random Base\", \"param_grid\":{}, \"verbose\": [False], \"model\":BaselineOnly, \"CV\":cv},\n",
    "           {\"name\":\"Baseline ALS\", \"param_grid\":{\"bsl_options\": {\"n_epochs\": [5, 10], \"reg_u\": [5, 10, 20], \"reg_i\": [5, 10, 20], \"method\": [\"als\"]}}, \"verbose\": [False], \"model\":BaselineOnly, \"CV\":cv},\n",
    "           {\"name\":\"Baseline SGD\", \"param_grid\":{\"bsl_options\": {\"n_epochs\": [5, 10],  \"learning_rate\": [0.005, 0.0005], \"reg\": [0.02, 0.01], \"method\": [\"sgd\"]}}, \"verbose\": [False], \"model\":BaselineOnly, \"CV\":cv},\n",
    "           {\"name\":\"Matrix factorization based\", \"param_grid\":{\"lr_all\":[0.007, 0.01, 0.15]}, \"verbose\": [False], \"model\":SVD, \"CV\":cv},\n",
    "           {\"name\":\"Matrix factorization based + implicit rating\", \"param_grid\":{\"lr_all\":[0.007, 0.01, 0.15]}, \"verbose\": [False], \"model\":SVDpp, \"CV\":cv}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81c4a7b-5a15-45b1-950c-f3d4c9385a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "targetedMetric = \"mae\"\n",
    "bestScoringModel = [np.inf, None, None]\n",
    "\n",
    "\n",
    "LOOCV = LeaveOneOut(n_splits=1, random_state=777)\n",
    "train_loocv, test_loocv  = LOOCV.split(data).__next__()\n",
    "for target in targets:\n",
    "    print(\"****** doing \", target)\n",
    "    np.random.seed(40)\n",
    "    scoringModel, modelParam, model = hyperTune( target[\"param_grid\"], data, target[\"model\"], targetedMetric, target[\"CV\"])\n",
    "    print(\"best mae for \", target[\"name\"], \":\", scoringModel, \" with parameters :\", target[\"param_grid\"])\n",
    "    if scoringModel < bestScoringModel[0]:\n",
    "        print(\"found new best tuned model !\")\n",
    "        bestScoringModel[0] = scoringModel\n",
    "        bestScoringModel[1] = modelParam\n",
    "        bestScoringModel[2] = model\n",
    "\n",
    "    get_hitrate_results(bestScoringModel[2](), train_loocv, test_loocv, 10, 2)\n",
    "    print(\"************************\")\n",
    "\n",
    "\n",
    "get_hitrate_results(bestScoringModel[2](), train_loocv, test_loocv, 10, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc3b1d6-e4f6-47ed-9eac-faf6b0ef6ad7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
